{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2d7329",
   "metadata": {},
   "source": [
    "## Relatório do Trabalho Final de Inteligência Artificial\n",
    "\n",
    "**Disciplina:** Inteligência Artificial\n",
    "\n",
    "**Data:** 18/12/24\n",
    "\n",
    "**Professors:** Edjard Mota \n",
    "\n",
    "**Turma:** EC01 & CB500\n",
    "\n",
    "**Aluno:** Aline Silva da Cunha          \n",
    "**Matrícula:** 22250558  \n",
    "\n",
    "**Aluno:** Lorena Pantoja dos Anjos      \n",
    "**Matrícula:** 22252592\n",
    "\n",
    "**Instituição:** Universidade Federal do Amazonas (UFAM)  \n",
    "\n",
    "**1. Introdução**\n",
    "\n",
    "Este trabalho final aborda o problema clássico de classificação de trens, utilizando técnicas neuro-simbólicas e algoritmos de clustering. A proposta é implementar soluções baseadas no exemplo do trem de Michalski, que categoriza trens indo para o leste ou oeste com base em suas características. Este problema é um marco em estudos de inteligência artificial por exemplificar a integração de lógica simbólica e aprendizado baseado em dados, oferecendo uma plataforma para explorar como o raciocínio humano pode ser modelado computacionalmente.\n",
    "\n",
    "A abordagem proposta neste trabalho se desdobra em três etapas principais:\n",
    "\n",
    "1. Aplicar clustering para agrupar trens com características similares, independente da direção.\n",
    "2. Gerar axiomas a partir dos clusters e treinar modelos LTN (Logic Tensor Network) para classificação.\n",
    "3. Comparar os resultados obtidos com modelos existentes e extrair regras explicativas a partir do modelo treinado.\n",
    "\n",
    "Além disso, este trabalho discute a importância de variáveis booleanas como uma ponte entre a representação lógica e o aprendizado por redes neurais, permitindo que o modelo interprete padrões complexos com maior transparência.\n",
    "\n",
    "**2. Referencial Teórico**\n",
    "\n",
    "O problema é inspirado no modelo de aprendizado neuro-simbólico proposto por Artur S. d’Avila Garcez, Krysia B. Broda e Dov M. Gabbay em *Neural-Symbolic Learning Systems Foundation*. Esse modelo busca combinar a capacidade de aprendizado e generalização das redes neurais com a habilidade de representar conhecimento e raciocinar logicamente, característica dos sistemas simbólicos. Essa integração é particularmente útil para problemas que exigem tanto o processamento de dados brutos quanto a aplicação de regras e axiomas previamente conhecidos.\n",
    "\n",
    "O uso de técnicas neuro-simbólicas é amplamente aplicável em áreas como processamento de linguagem natural, reconhecimento de padrões e sistemas de suporte à decisão. A lógica simbólica permite representar relações complexas de forma explícita, enquanto as redes neurais fornecem a capacidade de lidar com incertezas e variabilidade nos dados.\n",
    "\n",
    "**3. Metodologia**\n",
    "\n",
    "### 3.1. Agrupamento e geração de axiomas\n",
    "\n",
    "Os trens foram agrupados por similaridade utilizando algoritmos de clustering. Para realizar esse agrupamento, foram considerados os seguintes atributos principais:\n",
    "\n",
    "- **Quantidade de vagões:** valores entre 3 a 5, representando a estrutura básica de cada trem.\n",
    "- **Quantidade de cargas diferentes:** valores entre 1 a 4, que indicam a diversidade das cargas transportadas.\n",
    "- **Formato da carroceria do vagão:** incluindo opções como retângulo fechado, retângulo aberto, elipse, hexágono, entre outros.\n",
    "- **Tipo de carga no vagão:** representado por formas geométricas como círculo, hexágono, retângulo ou triângulo.\n",
    "- **Adjacência entre vagões:** uma série de variáveis booleanas indicando se tipos específicos de vagões ou cargas estão próximos uns dos outros.\n",
    "\n",
    "Essas variáveis booleanas, que assumem valores de Verdadeiro (V) ou Falso (F), foram fundamentais para capturar padrões como:\n",
    "- \"Existe um retângulo próximo de um triângulo.\"\n",
    "- \"Existe um círculo próximo de outro círculo.\"\n",
    "\n",
    "A partir dos clusters gerados, foram propostos axiomas lógicos que descrevem as relações observadas. Esses axiomas foram modelados por predicados, como:\n",
    "\n",
    "- **num\\_cars(t, nc):** número de vagões em um trem.\n",
    "- **shape(t, c, s):** formato da carroceria de um vagão.\n",
    "- **next\\_crc(t, c, x):** se há cargas em círculo adjacentes em vagões consecutivos.\n",
    "- **next\\_hex(t, c, x):** se há cargas em formato hexagonal adjacentes em vagões consecutivos.\n",
    "\n",
    "Essa etapa permitiu estabelecer uma base formal para o treinamento do modelo LTN, promovendo maior interpretabilidade dos resultados.\n",
    "\n",
    "### 3.2. Implementação de modelos LTN\n",
    "\n",
    "A implementação foi realizada utilizando a biblioteca LTNTorch, projetada especificamente para trabalhar com redes neurais que incorporam lógica simbólica. A arquitetura do modelo incluiu sub-redes especializadas, cada uma responsável por modelar um predicado ou relação lógica específica. Essas sub-redes foram então conectadas a uma rede principal, responsável por realizar a classificação final (leste ou oeste).\n",
    "\n",
    "O conjunto de dados foi dividido da seguinte forma:\n",
    "- **70% para treinamento:** utilizado para ajustar os pesos e parâmetros das redes.\n",
    "- **30% para validação:** utilizado para avaliar o desempenho do modelo em dados não vistos.\n",
    "\n",
    "A taxa de aprendizado e o número de épocas foram ajustados iterativamente para otimizar a performance, sendo observada uma estabilização no aprendizado após aproximadamente 200 épocas.\n",
    "\n",
    "### 3.3. Extração de regras\n",
    "\n",
    "Uma vez treinado, o modelo foi utilizado como base para a extração de regras interpretáveis. Para isso, foi implementada uma abordagem baseada em árvores de decisão, que mapeia as decisões da rede neural em representações lógicas explícitas. Isso permitiu identificar padrões como:\n",
    "- \"Se um trem tem vagões curtos e fechados, ele vai para o leste.\"\n",
    "- \"Se um trem possui mais de dois tipos diferentes de carga, ele segue para o leste.\"\n",
    "\n",
    "Essas regras foram validadas em relação aos dados originais, confirmando sua consistência com o comportamento observado nos clusters.\n",
    "\n",
    "**4. Resultados**\n",
    "\n",
    "### 4.1. Resultados dos clusters\n",
    "\n",
    "Os algoritmos de clustering identificaram grupos de trens com características comuns. Alguns padrões identificados incluem:\n",
    "\n",
    "- Trens com vagões curtos e teto fechado foram frequentemente associados à direção leste.\n",
    "- Trens com dois vagões ou com vagões de teto irregular tendem a se mover para o oeste.\n",
    "\n",
    "Os clusters não apenas agruparam os dados de forma coerente, mas também forneceram insights úteis para a formulação de axiomas e a estruturação do modelo LTN.\n",
    "\n",
    "### 4.2. Desempenho do modelo LTN\n",
    "\n",
    "Os modelos LTN apresentaram resultados consistentes, com métricas de desempenho como:\n",
    "\n",
    "- **Acurácia geral:** 87%.\n",
    "- **Erro em validação:** Apenas 13% dos casos testados apresentaram classificação incorreta.\n",
    "\n",
    "\n",
    "### 4.3. Extração de regras\n",
    "\n",
    "As regras extraídas das árvores de decisão confirmaram hipóteses preexistentes, como:\n",
    "\n",
    "1. Se um trem tem vagões curtos e fechados, ele vai para o leste.\n",
    "2. Se um trem possui mais de dois tipos diferentes de carga, ele segue para o leste.\n",
    "3. Trens com vagões de teto irregular geralmente seguem para o oeste.\n",
    "\n",
    "Essas regras foram comparadas com as teorias descritas no livro *Neural-Symbolic Learning Systems Foundation*, mostrando forte alinhamento com os padrões identificados na literatura. As variáveis booleanas (V/F) desempenharam um papel essencial na formulação e interpretação das regras.\n",
    "\n",
    "**5. Análise Comparativa**\n",
    "\n",
    "A implementação foi comparada com abordagens anteriores, como o modelo LTN descrito por Garcez. As regras extraídas demonstraram que o modelo proposto é capaz de capturar padrões relevantes e oferecer uma classificação robusta. A inclusão de novos predicados ampliou a capacidade explicativa do modelo, embora tenha introduzido desafios no treinamento devido ao aumento da complexidade.\n",
    "\n",
    "**6. Considerações Finais**\n",
    "\n",
    "Este trabalho destacou o potencial das técnicas neuro-simbólicas na resolução de problemas de classificação complexos. A abordagem combinou algoritmos de clustering para agrupar dados similares e modelos LTN para representar relações lógicas. A extração de regras trouxe clareza ao processo de classificação, permitindo compreender as decisões do modelo. O uso de variáveis booleanas (V/F) revelou-se crucial para capturar relações importantes entre os atributos dos trens.\n",
    "\n",
    "**7. Referências**\n",
    "\n",
    "\n",
    "- Craven, M., Shavlik, J. *Extracting Tree-Structured Representations of Trained Networks*. Advances in Neural Information Processing Systems.\n",
    "- Garcez, A.S., Broda, K.B., Gabbay, D.M. *Neural-Symbolic Learning Systems Foundation*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ddab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
